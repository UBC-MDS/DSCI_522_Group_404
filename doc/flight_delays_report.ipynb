{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "100-late_dep": "72.6",
     "late_dep": "27.4",
     "round(np.max(pd.read_csv('../results/accuracy.csv')['test_accuracy']),3)*100": "72.6"
    }
   },
   "source": [
    "## Predicting US domestic flight delays using flight details\n",
    "\n",
    "Group 404: Mike Chen, Lori Fang, Jarome Leslie\n",
    "\n",
    "### Summary\n",
    "\n",
    "In this project we aim to develop a classifier which predicts whether a US domestic flight will be delayed based on its characteristics. We compare Support Vector Machines (\"SVM\") and Logistic Regression classifiers which both resulted in a {{round(np.max(pd.read_csv('../results/accuracy.csv')['test_accuracy']),3)*100}}% accuracy rate on unseen validation data. Taking a closer look at the data, we observed that the status of a flight as delayed or not delayed is imbalanced with {{late_dep}}% of observations representing a delayed flight and {{100-late_dep}}% representing the proportion of flights that were on time. It appears that neither model does a good job of classifying delayed flights, even after parameter optimization. A second look at the features and the consideration of different classifiers may therefore be required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "On any given day there are approximately 87,000 flights in the skies of the United States (US National Oceanic and Atmospheric Administration). For business travellers trying to fit productivity into every hour of the day, knowing whether a flight will be delayed would help them avoid setting unrealistic meeting times. Here we endeavour to test whether a machine learning model can answer the question of whether a flight will be delayed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "IFrame(src=\"../results/chart1.html\", width = 1000, height = 400)": "\n        <iframe\n            width=\"1000\"\n            height=\"400\"\n            src=\"../results/chart1.html\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        "
    }
   },
   "source": [
    "## Methods\n",
    "\n",
    "### Data\n",
    "\n",
    "For this project, we selected US Deparment of Transportation's dataset on [2015 Flight Delays and Cancellations](https://www.kaggle.com/usdot/flight-delays#flights.csv.). This data is shared on Kaggle under a CC0: Public Domain license.   This dataset contains data for approximately 6 million domestic flights in the 2015 calender year with datetime-, airline- and flight-related features. Some datetime-related features include `YEAR`, `MONTH`, `DAY`, `DAY_OF_THE_WEEK`, `SCHEDULED_DEPARTURE`, `DEPARTURE_TIME`, `DEPARTURE_DELAY`, and  `ARRIVAL_TIME`. Some examples of the airline-related features are `AIRLINE`, `FLIGHT_NUMBER`, and `TAIL_NUMBER`. Lastly,  the flight-related features include features such as `ORIGIN_AIRPORT`, `DESTINATION_AIRPORT`, `DISTANCE`, `SCHEDULED_TIME`, `ELAPSED_TIME`,  and `AIR_TIME`.\n",
    "\n",
    "Taking a preliminary look at the data, we observe average departure delay for different US domestic carriers. Here we observe that Spirit Airways and United Airways experiences the largest average departure delays in 2015. Similarly, Alaska Airlines and Hawaiian Airlines recorded the lowest average departure delay times in the country for the same year. Our analysis will explore whether this feature has any predictive power.\n",
    "\n",
    "**Figure 1. Average departure delay for each airline**\n",
    "\n",
    "{{IFrame(src=\"../results/chart1.html\", width = 1000, height = 400)}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "pd.read_csv(\"../results/hyper_paramaters.csv\")[['C', 'gamma']]": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C</th>\n      <th>gamma</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.001</td>\n      <td>0.0001</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.010</td>\n      <td>0.0010</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.100</td>\n      <td>0.0100</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.000</td>\n      <td>0.1000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>10.000</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>100.000</td>\n      <td>10.0000</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1000.000</td>\n      <td>100.0000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
     "pd.read_csv('../results/accuracy.csv')['best_params'][0]": "&quot;{&#39;C&#39;: 0.001, &#39;gamma&#39;: 0.0001}&quot;",
     "pd.read_csv('../results/accuracy.csv')['best_params'][1]": "&quot;{&#39;C&#39;: 0.001}&quot;"
    }
   },
   "source": [
    "### Analysis\n",
    "\n",
    "To compare the SVM and Logistic regression we sought out to perform hyperparameter optimization for the following values of C, and gamma. From performing `GridSearchCV` over this set, we identified the optimal parameters for the SVM classifier as {{pd.read_csv('../results/accuracy.csv')['best_params'][0]}} and the optimal parameters for the logistic regression classifier as {{pd.read_csv('../results/accuracy.csv')['best_params'][1]}}.\n",
    "\n",
    "**Figure 2. Hyperparameters tested for optimization**\n",
    "\n",
    "{{pd.read_csv(\"../results/hyper_paramaters.csv\")[['C', 'gamma']]}}\n",
    "\n",
    "In addition, to minimize the bias of not taking into account all of the training data, we implemented 5-fold cross validation. As we embarked on this journey it became that our original 500,000 observation slice of full dataset was too large to process in this manner. Accordingly we pared down our analysis to a subset containing 8,000 training examples and 2,000 validation examples.  The R and Python programming languages (R Core Team 2019; Van Rossum and Drake 2009) and the following R and Python packages were used to perform the analysis:  docopt (de Jonge 2018), tidyverse (Wickham 2017), docopt (Keleshev 2014), RCurl (Lang 2020), testthat (Wickam 2011), Pandas (McKinney 2010), NumPy (Oliphant 2006). The code for this analysis may be found [here](https://github.com/UBC-MDS/DSCI_522_Group_404).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "pd.read_csv(\"../results/lgr_classification_report.csv\")": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>0</th>\n      <th>1</th>\n      <th>accuracy</th>\n      <th>macro avg</th>\n      <th>weighted avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>precision</td>\n      <td>0.726375</td>\n      <td>0.0</td>\n      <td>0.726375</td>\n      <td>0.363187</td>\n      <td>0.527621</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>recall</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.726375</td>\n      <td>0.500000</td>\n      <td>0.726375</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>f1-score</td>\n      <td>0.841503</td>\n      <td>0.0</td>\n      <td>0.726375</td>\n      <td>0.420752</td>\n      <td>0.611247</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>support</td>\n      <td>5811.000000</td>\n      <td>2189.0</td>\n      <td>0.726375</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
     "pd.read_csv(\"../results/svc_classification_report.csv\")": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>0</th>\n      <th>1</th>\n      <th>accuracy</th>\n      <th>macro avg</th>\n      <th>weighted avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>precision</td>\n      <td>0.726375</td>\n      <td>0.0</td>\n      <td>0.726375</td>\n      <td>0.363187</td>\n      <td>0.527621</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>recall</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.726375</td>\n      <td>0.500000</td>\n      <td>0.726375</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>f1-score</td>\n      <td>0.841503</td>\n      <td>0.0</td>\n      <td>0.726375</td>\n      <td>0.420752</td>\n      <td>0.611247</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>support</td>\n      <td>5811.000000</td>\n      <td>2189.0</td>\n      <td>0.726375</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
    }
   },
   "source": [
    "## Results & Discussion\n",
    "\n",
    "Using sklearn's classification report, we observe that the SVM and logistic regression models yield identical results. More specifically we observe that neither captures predictions for delayed flights as seen from the f1 score for the delayed group being zero.\n",
    "\n",
    "\n",
    "**Figure 3. Classification report for the SVM classifier**\n",
    "\n",
    "{{pd.read_csv(\"../results/svc_classification_report.csv\")}}\n",
    "\n",
    "**Figure 4. Classification report for the logistic regression classifier**\n",
    "\n",
    "{{pd.read_csv(\"../results/lgr_classification_report.csv\")}}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "\"Air Traffic.\" National Oceanic and Atmospheric Administration. Accessed January 25, 2020. <https://sos.noaa.gov/datasets/air-traffic/>\n",
    "\n",
    "Lang, D. (2020). RCurl: General Network (HTTP/FTP/...) Client Interface for R. R\n",
    "  package version 1.98-1.1. <https://CRAN.R-project.org/package=RCurl>\n",
    "\n",
    "de Jonge, E.  (2018). docopt: Command-Line Interface Specification Language. R package\n",
    "  version 0.6.1. <https://CRAN.R-project.org/package=docopt>\n",
    "\n",
    "McKinney, W., & others. (2010). Data structures for statistical computing in python. In Proceedings of the 9th Python in Science Conference (Vol. 445, pp. 51–56).\n",
    "\n",
    "Pedregosa, F., Varoquaux, Ga\"el, Gramfort, A., Michel, V., Thirion, B., Grisel, O., … others. (2011). Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12(Oct), 2825–2830.\n",
    "\n",
    "R Core Team. 2019. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n",
    "\n",
    "Oliphant, T. A guide to NumPy, USA: Trelgol Publishing, (2006).\n",
    "\n",
    "\"US Department of Transportation - 2015 Flight Delays and Cancellations.\" Kaggle Inc. Accessed January 15, 2020. <https://www.kaggle.com/usdot/flight-delays#flights.csv>\n",
    "\n",
    "Van Rossum, G., and Drake, F. 2009. Python 3 Reference Manual. Scotts Valley, CA: CreateSpace.\n",
    "\n",
    "Wickham, H. 2017. Tidyverse: Easily Install and Load the ’Tidyverse’. https://CRAN.R-project.org/package=tidyverse.\n",
    "\n",
    "Wickham, H., Hester, J., and Francois, R. (2018). readr: Read Rectangular Text Data. R\n",
    "  package version 1.3.1. https://CRAN.R-project.org/package=readr\n",
    "  \n",
    "Wickham, H. testthat: Get Started with Testing. The R Journal, vol. 3, no. 1, pp. 5--10,\n",
    "  2011\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables for report\n",
    "Test_acc = round(np.max(pd.read_csv('../results/accuracy.csv')['test_accuracy']),3)*100\n",
    "y_original = pd.read_csv('../data/y_test.csv')['Target']\n",
    "late_dep = round(np.sum(pd.read_csv('../data/y_test.csv')['Target'])/len(pd.read_csv('../data/y_test.csv')['Target'])*100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'C': 0.001, 'gamma': 0.0001}\n",
       "1                     {'C': 0.001}\n",
       "Name: best_params, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../results/accuracy.csv')['best_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
