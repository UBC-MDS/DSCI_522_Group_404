{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting US domestic flight delays using flight details\n",
    "\n",
    "Group 404: Mike Chen, Lori Fang, Jarome Leslie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "round(pd.read_csv('../results/accuracy.csv').loc[0][2]*100,1)": "60.0",
     "round(pd.read_csv('../results/accuracy.csv').loc[1][2]*100,1)": "57.1"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "In this project we aim to develop a classifier which predicts whether a US domestic flight will be delayed based on its characteristics, comparing the performance of Support Vector Machines (\"SVM\") and Logistic Regression classifiers. After optimizing for hyperparameters, the SVM resulted in a 72.6% test accuracy rate. \n",
    "\n",
    "In comparison, the Logistic Regression classifier achieved a 72.6% test accuracy rate. Our LGBM model only achieved a test accuracy of 72.3%. Comparing the results from the three models, It appears that neither model does a good job of classifying delayed flights, even after parameter optimization. A second look at the features and the consideration of different classifiers may therefore be required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.73775</td>\n",
       "      <td>0.726375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGR</td>\n",
       "      <td>0.73775</td>\n",
       "      <td>0.726375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.77125</td>\n",
       "      <td>0.722875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  train_accuracy  test_accuracy\n",
       "0        SVC         0.73775       0.726375\n",
       "1        LGR         0.73775       0.726375\n",
       "2       LGBM         0.77125       0.722875"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../results/accuracy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "On any given day there are approximately 87,000 flights in the skies of the United States (US National Oceanic and Atmospheric Administration). For business travellers trying to fit productivity into every hour of the day, knowing whether a flight will be delayed would help them avoid setting unrealistic meeting times. Here we endeavour to test whether a machine learning model can answer the question of whether a flight will be delayed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "### Data\n",
    "\n",
    "For this project, we selected US Deparment of Transportation's dataset on [2015 Flight Delays and Cancellations](https://www.kaggle.com/usdot/flight-delays#flights.csv.). This data is shared on Kaggle under a CC0: Public Domain license.   This dataset contains data for approximately 6 million domestic flights in the 2015 calender year with datetime-, airline- and flight-related features. Some datetime-related features include `YEAR`, `MONTH`, `DAY`, `DAY_OF_THE_WEEK`, `SCHEDULED_DEPARTURE`, `DEPARTURE_TIME`, `DEPARTURE_DELAY`, and  `ARRIVAL_TIME`. Some examples of the airline-related features are `AIRLINE`, `FLIGHT_NUMBER`, and `TAIL_NUMBER`. Lastly,  the flight-related features include features such as `ORIGIN_AIRPORT`, `DESTINATION_AIRPORT`, `DISTANCE`, `SCHEDULED_TIME`, `ELAPSED_TIME`,  and `AIR_TIME`.\n",
    "\n",
    "Taking a preliminary look at the data, we observe average departure delay for different US domestic carriers. Here we observe that Spirit Airways and United Airways experiences the largest average departure delays in 2015. Similarly, Alaska Airlines and Hawaiian Airlines recorded the lowest average departure delay times in the country for the same year. Our analysis will explore whether this feature has any predictive power.\n",
    "\n",
    "**Figure 1. Average departure delay for each airline**\n",
    "\n",
    "<img src=\"../results/chart1.png\" width = 500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "pd.read_csv(\"../results/hyper_parameters.csv\")[['C', 'gamma']]": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C</th>\n      <th>gamma</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.001</td>\n      <td>0.0001</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.010</td>\n      <td>0.0010</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.100</td>\n      <td>0.0100</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.000</td>\n      <td>0.1000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>10.000</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>100.000</td>\n      <td>10.0000</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1000.000</td>\n      <td>100.0000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
     "pd.read_csv('../results/accuracy.csv')['best_params'][0]": "&quot;{&#39;gamma&#39;: 0.0001, &#39;C&#39;: 10.0}&quot;",
     "pd.read_csv('../results/accuracy.csv')['best_params'][1]": "&quot;{&#39;C&#39;: 0.001}&quot;"
    }
   },
   "source": [
    "### Analysis\n",
    "\n",
    "To compare the SVM and Logistic regression we sought out to perform hyperparameter optimization for the following values of C, and gamma. From performing `GridSearchCV` over this set, we identified the optimal parameters for the SVM classifier as {{pd.read_csv('../results/accuracy.csv')['best_params'][0]}} and the optimal parameters for the logistic regression classifier as {{pd.read_csv('../results/accuracy.csv')['best_params'][1]}}.\n",
    "\n",
    "**Figure 2. Hyperparameters tested for optimization**\n",
    "\n",
    "{{pd.read_csv(\"../results/hyper_parameters.csv\")[['C', 'gamma']]}}\n",
    " \n",
    "\n",
    "In addition, to minimize the bias of not taking into account all of the training data, we implemented 5-fold cross validation. As we embarked on this journey it became that our original 500,000 observation slice of full dataset was too large to process in this manner. Accordingly we pared down our analysis to a subset containing 8,000 training examples and 2,000 validation examples.  The R and Python programming languages (R Core Team 2019; Van Rossum and Drake 2009) and the following R and Python packages were used to perform the analysis:  docopt (de Jonge 2018), tidyverse (Wickham 2017), docopt (Keleshev 2014), RCurl (Lang 2020), testthat (Wickam 2011), Pandas (McKinney 2010), NumPy (Oliphant 2006). The code for this analysis may be found [here](https://github.com/UBC-MDS/DSCI_522_Group_404).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 2. Hyperparameters tested for optimization (SVM and LGR)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000.000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          C     gamma\n",
       "0     0.001    0.0001\n",
       "1     0.010    0.0010\n",
       "2     0.100    0.0100\n",
       "3     1.000    0.1000\n",
       "4    10.000    1.0000\n",
       "5   100.000   10.0000\n",
       "6  1000.000  100.0000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../results/hyper_paramaters.csv\")[['C', 'gamma']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "pd.read_csv(\"../results/lgr_classification_report.csv\")": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>0</th>\n      <th>1</th>\n      <th>accuracy</th>\n      <th>macro avg</th>\n      <th>weighted avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>precision</td>\n      <td>0.570875</td>\n      <td>0.0</td>\n      <td>0.570875</td>\n      <td>0.285438</td>\n      <td>0.325898</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>recall</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.570875</td>\n      <td>0.500000</td>\n      <td>0.570875</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>f1-score</td>\n      <td>0.726824</td>\n      <td>0.0</td>\n      <td>0.570875</td>\n      <td>0.363412</td>\n      <td>0.414926</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>support</td>\n      <td>4567.000000</td>\n      <td>3433.0</td>\n      <td>0.570875</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
     "pd.read_csv(\"../results/svc_classification_report.csv\")": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>0</th>\n      <th>1</th>\n      <th>accuracy</th>\n      <th>macro avg</th>\n      <th>weighted avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>precision</td>\n      <td>0.645559</td>\n      <td>0.535823</td>\n      <td>0.600375</td>\n      <td>0.590691</td>\n      <td>0.598468</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>recall</td>\n      <td>0.665207</td>\n      <td>0.514128</td>\n      <td>0.600375</td>\n      <td>0.589667</td>\n      <td>0.600375</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>f1-score</td>\n      <td>0.655236</td>\n      <td>0.524751</td>\n      <td>0.600375</td>\n      <td>0.589993</td>\n      <td>0.599241</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>support</td>\n      <td>4567.000000</td>\n      <td>3433.000000</td>\n      <td>0.600375</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
    }
   },
   "source": [
    "## Results, Critiques & Discussion\n",
    "\n",
    "Our original reserach question is a classification problem of predicting which flights are likely to be delayed. The motivation for this study is to help business travel passengers in making plans when they travel on the amount of buffer time they should keep in their schedules when travelling before making meeting commitments. \n",
    "\n",
    "From EDA, we noticed that our dataset is unbalanced. Therefore, we'll be relying heavily on metrics such as the f1 score, precision and recall to determine whether the model is capable of predicting whether or not a flight would be delayed or not. Using sklearn's classification report, we observe that the SVM and logistic regression models yield identical results. More specifically we observe that neither captures predictions for delayed flights as seen from the f1 score for the delayed group being zero. The LGBM Classifier was able to capture predictions for the delayed flights, but the f1 score, recall and precision are all horribly low. \n",
    "\n",
    "A precision and recall score of 0 in the SVM and Logistic Regression Classifiers means that neither of the models are capable of getting a single prediction right! In the LGBM Classifier we were able to achieve a precision of roughly 45%, which means that roughly 45% of our results are actually relevant. However, LGBM's recall score of sub 10% means that less that 10% of actually relevant results are correctly predicted by our model. With these abysmal performance, we have a lot of room for improvement. \n",
    "\n",
    "\n",
    "One critique of our anaylsis is our choice to reduce the number of examples in our dataset. Our original database is huge with roughly 6 million examples and 40 features. We wanted to reduce the size of the dataset, so it'll be faster to perform wrangling, EDA and modeling. This is the reason why we reduced the training and validation dataset to only include 8000 examples each. We believe with more training examples, our model might've gotten a better score. \n",
    "\n",
    "However, we believe the biggest flaw in our analysis is our method of selecting features. We selected our features based partly on convenience and on \"intuition\". We wanted to only keep a few features (below 5) in order to keep the size of our training and predicting dataset small, so we eliminated a lot of the potential features. The features that we used were only kept based on our limited knowledge of airline travel. We thought features such as `DISTANCE`, `MONTH` and etc were important. We didn't think of performing any correlation analysis on our features, nor utilize any feature selection techniques such as Recursive Feature Elimination or Search and Score Methods.\n",
    "\n",
    "\n",
    "## Future Improvements\n",
    "\n",
    "As a team we think the most crucial future improvement to make is to include a feature selection technique such as Forward Selection. \n",
    "\n",
    "Other improvements we thought of are to increase the size of the training and test datasets and to include additional classifiers such as random forest and etc.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 3. Classification report for the SVM classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.726375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.726375</td>\n",
       "      <td>0.363187</td>\n",
       "      <td>0.527621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.726375</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.726375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.841503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.726375</td>\n",
       "      <td>0.420752</td>\n",
       "      <td>0.611247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>support</td>\n",
       "      <td>5811.000000</td>\n",
       "      <td>2189.0</td>\n",
       "      <td>0.726375</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0            0       1  accuracy    macro avg  weighted avg\n",
       "0  precision     0.726375     0.0  0.726375     0.363187      0.527621\n",
       "1     recall     1.000000     0.0  0.726375     0.500000      0.726375\n",
       "2   f1-score     0.841503     0.0  0.726375     0.420752      0.611247\n",
       "3    support  5811.000000  2189.0  0.726375  8000.000000   8000.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../results/svc_classification_report.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 4. Classification report for the logistic regression classifier**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.726375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.726375</td>\n",
       "      <td>0.363187</td>\n",
       "      <td>0.527621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.726375</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.726375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.841503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.726375</td>\n",
       "      <td>0.420752</td>\n",
       "      <td>0.611247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>support</td>\n",
       "      <td>5811.000000</td>\n",
       "      <td>2189.0</td>\n",
       "      <td>0.726375</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0            0       1  accuracy    macro avg  weighted avg\n",
       "0  precision     0.726375     0.0  0.726375     0.363187      0.527621\n",
       "1     recall     1.000000     0.0  0.726375     0.500000      0.726375\n",
       "2   f1-score     0.841503     0.0  0.726375     0.420752      0.611247\n",
       "3    support  5811.000000  2189.0  0.726375  8000.000000   8000.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../results/lgr_classification_report.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 5. Classification report for the lgbm classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.733195</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.722875</td>\n",
       "      <td>0.592788</td>\n",
       "      <td>0.656357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.972294</td>\n",
       "      <td>0.060758</td>\n",
       "      <td>0.722875</td>\n",
       "      <td>0.516526</td>\n",
       "      <td>0.722875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.835984</td>\n",
       "      <td>0.107128</td>\n",
       "      <td>0.722875</td>\n",
       "      <td>0.471556</td>\n",
       "      <td>0.636551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>support</td>\n",
       "      <td>5811.000000</td>\n",
       "      <td>2189.000000</td>\n",
       "      <td>0.722875</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0            0            1  accuracy    macro avg  weighted avg\n",
       "0  precision     0.733195     0.452381  0.722875     0.592788      0.656357\n",
       "1     recall     0.972294     0.060758  0.722875     0.516526      0.722875\n",
       "2   f1-score     0.835984     0.107128  0.722875     0.471556      0.636551\n",
       "3    support  5811.000000  2189.000000  0.722875  8000.000000   8000.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../results/lgbm_classification_report.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "\"Air Traffic.\" National Oceanic and Atmospheric Administration. Accessed January 25, 2020. <https://sos.noaa.gov/datasets/air-traffic/>\n",
    "\n",
    "Lang, D. (2020). RCurl: General Network (HTTP/FTP/...) Client Interface for R. R\n",
    "  package version 1.98-1.1. <https://CRAN.R-project.org/package=RCurl>\n",
    "\n",
    "de Jonge, E.  (2018). docopt: Command-Line Interface Specification Language. R package\n",
    "  version 0.6.1. <https://CRAN.R-project.org/package=docopt>\n",
    "\n",
    "McKinney, W., & others. (2010). Data structures for statistical computing in python. In Proceedings of the 9th Python in Science Conference (Vol. 445, pp. 51–56).\n",
    "\n",
    "Pedregosa, F., Varoquaux, Ga\"el, Gramfort, A., Michel, V., Thirion, B., Grisel, O., … others. (2011). Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12(Oct), 2825–2830.\n",
    "\n",
    "R Core Team. 2019. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n",
    "\n",
    "Oliphant, T. A guide to NumPy, USA: Trelgol Publishing, (2006).\n",
    "\n",
    "\"US Department of Transportation - 2015 Flight Delays and Cancellations.\" Kaggle Inc. Accessed January 15, 2020. <https://www.kaggle.com/usdot/flight-delays#flights.csv>\n",
    "\n",
    "Van Rossum, G., and Drake, F. 2009. Python 3 Reference Manual. Scotts Valley, CA: CreateSpace.\n",
    "\n",
    "Wickham, H. 2017. Tidyverse: Easily Install and Load the ’Tidyverse’. https://CRAN.R-project.org/package=tidyverse.\n",
    "\n",
    "Wickham, H., Hester, J., and Francois, R. (2018). readr: Read Rectangular Text Data. R\n",
    "  package version 1.3.1. https://CRAN.R-project.org/package=readr\n",
    "  \n",
    "Wickham, H. testthat: Get Started with Testing. The R Journal, vol. 3, no. 1, pp. 5--10,\n",
    "  2011\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
